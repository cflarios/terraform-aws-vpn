name: ðŸš€ Deploy VPN Infrastructure

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment name'
        required: true
        default: 'dev'
        type: string
      aws_region:
        description: 'AWS region for deployment'
        required: true
        default: 'us-east-1'
        type: choice
        options:
          - 'us-east-1'
          - 'us-east-2'
          - 'us-west-1'
          - 'us-west-2'
          - 'eu-west-1'
          - 'eu-west-2'
          - 'eu-central-1'
          - 'ap-southeast-1'
          - 'ap-southeast-2'
          - 'ap-northeast-1'
      instance_type:
        description: 'EC2 instance type'
        required: true
        default: 't3.micro'
        type: choice
        options:
          - 't3.micro'
          - 't3.small'
          - 't3.medium'
      wireguard_peers:
        description: 'Number of WireGuard clients'
        required: true
        default: '3'
        type: string

env:
  AWS_REGION: ${{ github.event.inputs.aws_region }}
  TF_VAR_aws_region: ${{ github.event.inputs.aws_region }}
  TF_VAR_environment: ${{ github.event.inputs.environment }}
  TF_VAR_instance_type: ${{ github.event.inputs.instance_type }}

jobs:
  setup-backend:
    name: ðŸ”§ Setup Terraform Backend
    runs-on: ubuntu-latest
    
    outputs:
      backend_bucket: ${{ steps.setup_backend.outputs.backend_bucket }}
      backend_table: ${{ steps.setup_backend.outputs.backend_table }}
      
    steps:
      - name: ðŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ðŸ”§ Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: ðŸ—ï¸ Setup Terraform Backend Infrastructure
        id: setup_backend
        run: |
          # Try to find existing backend configuration first
          echo "ðŸ” Checking for existing backend configuration..."
          
          if aws ssm get-parameter --name "/vpn/${{ github.event.inputs.environment }}/backend-bucket" 2>/dev/null; then
            # Use existing backend
            BUCKET_NAME=$(aws ssm get-parameter \
              --name "/vpn/${{ github.event.inputs.environment }}/backend-bucket" \
              --query 'Parameter.Value' \
              --output text)
            
            TABLE_NAME=$(aws ssm get-parameter \
              --name "/vpn/${{ github.event.inputs.environment }}/backend-table" \
              --query 'Parameter.Value' \
              --output text)
            
            echo "âœ… Found existing backend configuration:"
            echo "   ðŸª£ S3 Bucket: $BUCKET_NAME"
            echo "   ðŸ—„ï¸ DynamoDB Table: $TABLE_NAME"
          else
            # Create new backend
            echo "ðŸ—ï¸ Creating new backend infrastructure..."
            RANDOM_ID=$(openssl rand -hex 4)
            BUCKET_NAME="terraform-state-vpn-${RANDOM_ID}"
            TABLE_NAME="terraform-state-locks-vpn"
            
            echo "ðŸª£ Creating S3 bucket: $BUCKET_NAME"
            
            # Create S3 bucket for Terraform state (fix for us-east-1)
            if [ "${{ env.AWS_REGION }}" = "us-east-1" ]; then
              aws s3api create-bucket --bucket "$BUCKET_NAME" --region ${{ env.AWS_REGION }}
            else
              aws s3api create-bucket \
                --bucket "$BUCKET_NAME" \
                --region ${{ env.AWS_REGION }} \
                --create-bucket-configuration LocationConstraint=${{ env.AWS_REGION }}
            fi
            
            # Enable versioning
            aws s3api put-bucket-versioning \
              --bucket "$BUCKET_NAME" \
              --versioning-configuration Status=Enabled
            
            # Enable encryption
            aws s3api put-bucket-encryption \
              --bucket "$BUCKET_NAME" \
              --server-side-encryption-configuration '{
                "Rules": [
                  {
                    "ApplyServerSideEncryptionByDefault": {
                      "SSEAlgorithm": "AES256"
                    }
                  }
                ]
              }'
            
            # Block public access
            aws s3api put-public-access-block \
              --bucket "$BUCKET_NAME" \
              --public-access-block-configuration \
              BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
            
            echo "âœ… S3 bucket $BUCKET_NAME created successfully"
            
            echo "ðŸ—„ï¸ Creating DynamoDB table: $TABLE_NAME"
            
            # Check if table already exists
            if aws dynamodb describe-table --table-name "$TABLE_NAME" 2>/dev/null; then
              echo "âœ… DynamoDB table $TABLE_NAME already exists"
            else
              # Create DynamoDB table for state locking
              aws dynamodb create-table \
                --table-name "$TABLE_NAME" \
                --attribute-definitions AttributeName=LockID,AttributeType=S \
                --key-schema AttributeName=LockID,KeyType=HASH \
                --billing-mode PAY_PER_REQUEST \
                --sse-specification Enabled=true
              
              # Wait for table to be active
              echo "â³ Waiting for DynamoDB table to be active..."
              aws dynamodb wait table-exists --table-name "$TABLE_NAME"
              echo "âœ… DynamoDB table $TABLE_NAME created successfully"
            fi
            
            # Store backend configuration for future use
            aws ssm put-parameter \
              --name "/vpn/${{ github.event.inputs.environment }}/backend-bucket" \
              --value "$BUCKET_NAME" \
              --type "String" \
              --overwrite \
              --description "Terraform Backend S3 Bucket"
            
            aws ssm put-parameter \
              --name "/vpn/${{ github.event.inputs.environment }}/backend-table" \
              --value "$TABLE_NAME" \
              --type "String" \
              --overwrite \
              --description "Terraform Backend DynamoDB Table"
          fi
          
          # Store configuration in GitHub environment
          echo "backend_bucket=$BUCKET_NAME" >> $GITHUB_OUTPUT
          echo "backend_table=$TABLE_NAME" >> $GITHUB_OUTPUT
          
          echo "ðŸŽ‰ Backend setup completed!"
          echo "ðŸ“‹ Configuration:"
          echo "   ðŸª£ S3 Bucket: $BUCKET_NAME"
          echo "   ðŸ—„ï¸ DynamoDB Table: $TABLE_NAME"
          echo "   ðŸŒ Region: ${{ env.AWS_REGION }}"

  deploy-infrastructure:
    name: ðŸ—ï¸ Deploy Infrastructure
    runs-on: ubuntu-latest
    needs: setup-backend
    
    outputs:
      instance_ip: ${{ steps.terraform_output.outputs.instance_ip }}
      
    steps:
      - name: ðŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ðŸ”§ Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: ðŸ—ï¸ Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.5.0"

      - name: ðŸ”‘ Generate SSH Key
        id: ssh_key
        run: |
          mkdir -p ~/.ssh
          ssh-keygen -t rsa -b 4096 -f ~/.ssh/vpn-server-key -N "" -C "github-actions-vpn-key-$(date +%s)"
          chmod 600 ~/.ssh/vpn-server-key
          chmod 644 ~/.ssh/vpn-server-key.pub
          echo "SSH key generated successfully"

      - name: ðŸ’¾ Store SSH Keys in AWS Parameter Store
        run: |
          # Store private key
          aws ssm put-parameter \
            --name "/vpn/${{ github.event.inputs.environment }}/ssh-private-key" \
            --value "$(cat ~/.ssh/vpn-server-key)" \
            --type "SecureString" \
            --overwrite \
            --description "VPN SSH Private Key for ${{ github.event.inputs.environment }}"
          
          # Store public key
          aws ssm put-parameter \
            --name "/vpn/${{ github.event.inputs.environment }}/ssh-public-key" \
            --value "$(cat ~/.ssh/vpn-server-key.pub)" \
            --type "String" \
            --overwrite \
            --description "VPN SSH Public Key for ${{ github.event.inputs.environment }}"
          
          echo "âœ… SSH keys stored in Parameter Store"

      - name: ðŸš€ Terraform Init with Remote Backend
        working-directory: ./terraform
        run: |
          terraform init \
            -backend-config="bucket=${{ needs.setup-backend.outputs.backend_bucket }}" \
            -backend-config="key=vpn-${{ github.event.inputs.environment }}/terraform.tfstate" \
            -backend-config="region=${{ env.AWS_REGION }}" \
            -backend-config="encrypt=true" \
            -backend-config="dynamodb_table=${{ needs.setup-backend.outputs.backend_table }}"

      - name: ðŸ” Debug Backend Configuration
        working-directory: ./terraform
        run: |
          echo "ðŸ” Debugging Terraform backend configuration..."
          echo "Backend bucket: ${{ needs.setup-backend.outputs.backend_bucket }}"
          echo "Backend table: ${{ needs.setup-backend.outputs.backend_table }}"
          echo "State key: vpn-${{ github.event.inputs.environment }}/terraform.tfstate"
          
          # Check if .terraform directory exists and what's in it
          if [ -d .terraform ]; then
            echo "ðŸ“ .terraform directory contents:"
            ls -la .terraform/
            if [ -f .terraform/terraform.tfstate ]; then
              echo "ðŸ“„ .terraform/terraform.tfstate exists (this indicates local backend)"
            fi
          fi
          
          # Show terraform configuration
          echo "ðŸ”§ Terraform configuration:"
          terraform version
          echo "Backend configuration in use:"
          cat .terraform/terraform.tfstate 2>/dev/null || echo "No local backend config found"

      - name: ðŸ“‹ Terraform Plan
        working-directory: ./terraform
        run: |
          # Pass SSH public key as variable
          export TF_VAR_ssh_public_key="$(cat ~/.ssh/vpn-server-key.pub)"
          terraform plan -out=tfplan

      - name: âœ… Terraform Apply
        working-directory: ./terraform
        run: |
          # Pass SSH public key as variable
          export TF_VAR_ssh_public_key="$(cat ~/.ssh/vpn-server-key.pub)"
          terraform apply -auto-approve tfplan

      - name: ðŸ” Verify State Storage in S3
        run: |
          echo "ðŸ” Verifying that Terraform state was saved to S3..."
          BUCKET="${{ needs.setup-backend.outputs.backend_bucket }}"
          STATE_KEY="vpn-${{ github.event.inputs.environment }}/terraform.tfstate"
          
          echo "Checking for state file in S3: s3://$BUCKET/$STATE_KEY"
          
          if aws s3api head-object --bucket "$BUCKET" --key "$STATE_KEY" 2>/dev/null; then
            echo "âœ… State file found in S3!"
            
            # Get file size and last modified
            aws s3api head-object --bucket "$BUCKET" --key "$STATE_KEY" \
              --query '{Size: ContentLength, LastModified: LastModified}' \
              --output table
            
            echo "ðŸ“Š State file contents preview:"
            aws s3 cp "s3://$BUCKET/$STATE_KEY" - | head -20
          else
            echo "âŒ State file NOT found in S3!"
            echo "This indicates the state is being stored locally instead of in S3."
            
            # List all objects in bucket to see what's there
            echo "ðŸ“‹ Current S3 bucket contents:"
            aws s3 ls "s3://$BUCKET/" --recursive || echo "Bucket is empty"
          fi

      - name: ï¿½ Verify State Saved to S3
        working-directory: ./terraform
        run: |
          echo "ðŸ” Verifying that state was saved to S3..."
          
          # Check if state exists in S3
          if aws s3 ls "s3://${{ needs.setup-backend.outputs.backend_bucket }}/vpn-${{ github.event.inputs.environment }}/terraform.tfstate"; then
            echo "âœ… SUCCESS: State file found in S3!"
            aws s3 ls "s3://${{ needs.setup-backend.outputs.backend_bucket }}/vpn-${{ github.event.inputs.environment }}/" --human-readable
          else
            echo "âŒ ERROR: State file NOT found in S3!"
            echo "ðŸ” Checking what's in the bucket:"
            aws s3 ls "s3://${{ needs.setup-backend.outputs.backend_bucket }}/" --recursive || echo "Bucket appears empty"
            
            echo "ðŸ” Checking for local state (which shouldn't exist):"
            ls -la terraform.tfstate* || echo "No local state files"
            
            echo "âš ï¸  This means destroy will not work properly!"
          fi
          
          # Also check DynamoDB locks
          echo "ðŸ” Checking DynamoDB state locks..."
          aws dynamodb scan --table-name "${{ needs.setup-backend.outputs.backend_table }}" --select "COUNT" || echo "No locks found"

      - name: ï¿½ðŸ“¤ Get Terraform Outputs
        id: terraform_output
        working-directory: ./terraform
        run: |
          INSTANCE_IP=$(terraform output -raw instance_public_ip)
          echo "instance_ip=$INSTANCE_IP" >> $GITHUB_OUTPUT
          echo "Instance IP: $INSTANCE_IP"
          
          # Store instance IP in Parameter Store for destroy workflow and future use
          aws ssm put-parameter \
            --name "/vpn/${{ github.event.inputs.environment }}/instance-ip" \
            --value "$INSTANCE_IP" \
            --type "String" \
            --overwrite \
            --description "VPN Instance IP for ${{ github.event.inputs.environment }}"

      - name: ðŸ“Š Show Deployment Summary
        run: |
          echo "ðŸŽ‰ Infrastructure deployed successfully!"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "ðŸŒ Environment: ${{ github.event.inputs.environment }}"
          echo "ðŸ–¥ï¸  Instance Type: ${{ github.event.inputs.instance_type }}"
          echo "ðŸŒ Instance IP: ${{ steps.terraform_output.outputs.instance_ip }}"
          echo "ðŸ“¦ WireGuard Peers: ${{ github.event.inputs.wireguard_peers }}"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

  configure-wireguard:
    name: ðŸ”§ Configure WireGuard
    runs-on: ubuntu-latest
    needs: [setup-backend, deploy-infrastructure]
    
    steps:
      - name: ðŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ðŸ”§ Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: ðŸ”‘ Retrieve SSH Keys from Parameter Store
        run: |
          mkdir -p ~/.ssh
          
          # Get private key
          aws ssm get-parameter \
            --name "/vpn/${{ github.event.inputs.environment }}/ssh-private-key" \
            --with-decryption \
            --query 'Parameter.Value' \
            --output text > ~/.ssh/vpn-server-key
          
          # Get public key
          aws ssm get-parameter \
            --name "/vpn/${{ github.event.inputs.environment }}/ssh-public-key" \
            --query 'Parameter.Value' \
            --output text > ~/.ssh/vpn-server-key.pub
          
          chmod 600 ~/.ssh/vpn-server-key
          chmod 644 ~/.ssh/vpn-server-key.pub
          
          echo "âœ… SSH keys retrieved from Parameter Store"

      - name: ðŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: ðŸ“¦ Install Ansible
        run: |
          python -m pip install --upgrade pip
          pip install ansible

      - name: ðŸ“ Update Ansible inventory
        run: |
          echo "[vpn_servers]" > ansible/inventory.ini
          echo "vpn-server ansible_host=${{ needs.deploy-infrastructure.outputs.instance_ip }} ansible_user=ubuntu ansible_ssh_private_key_file=~/.ssh/vpn-server-key ansible_ssh_common_args='-o StrictHostKeyChecking=no'" >> ansible/inventory.ini

      - name: ðŸ“ Update WireGuard peers configuration
        run: |
          sed -i "s/peers: 3/peers: ${{ github.event.inputs.wireguard_peers }}/" ansible/group_vars/all.yml

      - name: â³ Wait for EC2 instance to be ready
        run: |
          echo "â³ Waiting for EC2 instance to be ready for SSH..."
          INSTANCE_IP="${{ needs.deploy-infrastructure.outputs.instance_ip }}"
          
          for i in {1..30}; do
            if ssh -i ~/.ssh/vpn-server-key -o ConnectTimeout=10 -o StrictHostKeyChecking=no ubuntu@$INSTANCE_IP "echo 'SSH Ready'" 2>/dev/null; then
              echo "âœ… EC2 instance is ready!"
              break
            fi
            echo "â³ Attempt $i/30: Instance not ready yet, waiting 30 seconds..."
            sleep 30
          done

      - name: ðŸš€ Run Ansible Playbook
        working-directory: ./ansible
        run: |
          ansible-playbook -i inventory.ini site.yml

      - name: ðŸŽ‰ Show Final Instructions
        run: |
          INSTANCE_IP="${{ needs.deploy-infrastructure.outputs.instance_ip }}"
          echo "ðŸŽŠ VPN Server Ready!"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "ðŸŒ Server IP: $INSTANCE_IP"
          echo "ðŸŒ Web Interface: http://$INSTANCE_IP:8080"
          echo "ðŸ“± WireGuard Clients: ${{ github.event.inputs.wireguard_peers }}"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ðŸ“‹ Next Steps:"
          echo "1. ðŸŒ Go to: http://$INSTANCE_IP:8080"
          echo "2. ðŸ“± Download .conf files for desktop clients"
          echo "3. ðŸ“± Download .png files (QR codes) for mobile"
          echo "4. ðŸ”§ Import configs into WireGuard clients"
          echo "5. ðŸš€ Connect and enjoy your VPN!"
          echo ""
          echo "ðŸ’¡ To destroy this infrastructure:"
          echo "   Go to Actions â†’ 'Destroy VPN Infrastructure'"
          echo "   Enter 'DESTROY' to confirm"

      - name: ðŸ“Š Create Deployment Summary
        run: |
          INSTANCE_IP="${{ needs.deploy-infrastructure.outputs.instance_ip }}"
          cat >> $GITHUB_STEP_SUMMARY << EOF
          # ðŸŽ‰ VPN Deployment Successful!
          
          ## ðŸ“‹ Deployment Information
          - **Environment**: ${{ github.event.inputs.environment }}
          - **Instance Type**: ${{ github.event.inputs.instance_type }}
          - **Instance IP**: $INSTANCE_IP
          - **WireGuard Clients**: ${{ github.event.inputs.wireguard_peers }}
          - **Backend Bucket**: ${{ needs.setup-backend.outputs.backend_bucket }}
          - **Backend Table**: ${{ needs.setup-backend.outputs.backend_table }}
          
          ## ðŸ“± Access Your VPN
          ðŸŒ **Web Interface**: [http://$INSTANCE_IP:8080](http://$INSTANCE_IP:8080)
          
          ## ðŸ”§ Management Commands
          \`\`\`bash
          # SSH Access
          ssh -i ~/.ssh/vpn-server-key ubuntu@$INSTANCE_IP
          
          # Check WireGuard Status  
          ssh -i ~/.ssh/vpn-server-key ubuntu@$INSTANCE_IP 'sudo docker logs wireguard'
          \`\`\`
          
          ## âš ï¸ Important
          - Download your VPN configurations from the web interface
          - **Remember to destroy** the infrastructure when finished
          - Use the **"Destroy VPN Infrastructure"** workflow to clean up
          EOF